{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Dataset (10 image categories)\n",
    "\n",
    "Attempts to build a state-of-the-art model. Benchmarks can be found at https://paperswithcode.com/sota/image-classification-on-cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transform images to tensors and normalize when loaded\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) # mean of 0.5 for each channel, sd of 0.5 for each channel\n",
    "])\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Create the train and test dataloaders\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Create the class labels\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9ef12497f0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_image = next(iter(train_loader))[0][0]\n",
    "print(example_image.shape)\n",
    "np_image = example_image.numpy()\n",
    "plt.imshow(np.transpose(np_image, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test Loops\n",
    "\n",
    "Creates train & test loops that can be used with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(\n",
    "    model: nn.Module, \n",
    "    loss_function, \n",
    "    learning_rate: float = 0.001, \n",
    "    epochs: int = 4) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Model\n",
    "    loss_function: Loss function (e.g. `nn.CrossEntropyLoss()`)\n",
    "    learning_rate: Learning rate\n",
    "    epochs: Number of epochs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: Accurancy\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    # For each epoch\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "         # Set a running loss\n",
    "        running_loss = 0.\n",
    "\n",
    "        # Go through each batch\n",
    "        for data in train_loader:\n",
    "            # Each batch contains [inputs, labels]\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            # Reset the model parameter gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        time_taken = time.time() - start_time\n",
    "        print('Epoch %d, loss %.3f, time %.3f' % (epoch + 1, running_loss, time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    Check the model accuracy with the test data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: Accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise counters\n",
    "    predictions_count = 0\n",
    "    correct_count = 0\n",
    "    \n",
    "    # For each batch\n",
    "    for data in test_loader:\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        \n",
    "        # Get the predictions\n",
    "        outputs = model(inputs)\n",
    "        predictions = outputs.argmax(1)\n",
    "        correct = predictions == labels\n",
    "        \n",
    "        # Increment the counters\n",
    "        predictions_count += correct.shape[0]\n",
    "        correct_count += correct.type(torch.float).sum().item()\n",
    "        \n",
    "    # Return the accuracy percentage\n",
    "    accuracy = correct_count/predictions_count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline CNN\n",
    "\n",
    "Taken from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n",
    "\n",
    "Note accuracy appears to make most of the gains by epoch 4 in previous testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 5633.576, time 7.763\n",
      "Epoch 2, loss 4813.185, time 15.781\n",
      "Epoch 3, loss 4483.288, time 23.595\n",
      "Epoch 4, loss 4248.014, time 31.441\n",
      "\n",
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5043"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BaseLineCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5) # Flatten each image to a vector\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "baseline = BaseLineCNN()\n",
    "baseline.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(baseline, criterion)\n",
    "\n",
    "print(\"\\nAccuracy:\")\n",
    "test(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 5670.843, time 8.275\n",
      "Epoch 2, loss 4828.096, time 16.888\n",
      "Epoch 3, loss 4496.578, time 25.391\n",
      "Epoch 4, loss 4268.337, time 34.045\n",
      "\n",
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4992"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VanillaMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32 * 32 * 3) # Flatten each image to a vector\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "vanilla = VanillaMLP()\n",
    "vanilla.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(vanilla, criterion)\n",
    "\n",
    "print(\"\\nAccuracy:\")\n",
    "test(vanilla)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
